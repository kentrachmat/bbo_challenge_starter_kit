{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bayesmark\n",
      "  Downloading bayesmark-0.0.8.tar.gz (86 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.9/86.9 kB\u001b[0m \u001b[31m911.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: scipy>=1.2.0 in /Users/kentrachmat/opt/anaconda3/lib/python3.9/site-packages (from bayesmark) (1.7.3)\n",
      "Requirement already satisfied: pandas>=0.24.0 in /Users/kentrachmat/opt/anaconda3/lib/python3.9/site-packages (from bayesmark) (1.4.2)\n",
      "Collecting pathvalidate>=0.29.0 (from bayesmark)\n",
      "  Downloading pathvalidate-3.2.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: numpy>=1.16.1 in /Users/kentrachmat/opt/anaconda3/lib/python3.9/site-packages (from bayesmark) (1.21.5)\n",
      "Collecting GitPython>=2.1.11 (from bayesmark)\n",
      "  Downloading GitPython-3.1.41-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: importlib-metadata>=0.18 in /Users/kentrachmat/opt/anaconda3/lib/python3.9/site-packages (from bayesmark) (4.11.3)\n",
      "Requirement already satisfied: scikit-learn>=0.20.2 in /Users/kentrachmat/opt/anaconda3/lib/python3.9/site-packages (from bayesmark) (0.24.2)\n",
      "Requirement already satisfied: xarray>=0.12.2 in /Users/kentrachmat/opt/anaconda3/lib/python3.9/site-packages (from bayesmark) (0.20.1)\n",
      "Collecting gitdb<5,>=4.0.1 (from GitPython>=2.1.11->bayesmark)\n",
      "  Downloading gitdb-4.0.11-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/kentrachmat/opt/anaconda3/lib/python3.9/site-packages (from importlib-metadata>=0.18->bayesmark) (3.7.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /Users/kentrachmat/opt/anaconda3/lib/python3.9/site-packages (from pandas>=0.24.0->bayesmark) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/kentrachmat/opt/anaconda3/lib/python3.9/site-packages (from pandas>=0.24.0->bayesmark) (2021.3)\n",
      "Requirement already satisfied: joblib>=0.11 in /Users/kentrachmat/opt/anaconda3/lib/python3.9/site-packages (from scikit-learn>=0.20.2->bayesmark) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/kentrachmat/opt/anaconda3/lib/python3.9/site-packages (from scikit-learn>=0.20.2->bayesmark) (2.2.0)\n",
      "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython>=2.1.11->bayesmark)\n",
      "  Downloading smmap-5.0.1-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: six>=1.5 in /Users/kentrachmat/opt/anaconda3/lib/python3.9/site-packages (from python-dateutil>=2.8.1->pandas>=0.24.0->bayesmark) (1.16.0)\n",
      "Downloading GitPython-3.1.41-py3-none-any.whl (196 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.4/196.4 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m\u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pathvalidate-3.2.0-py3-none-any.whl (23 kB)\n",
      "Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m772.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m6m0:00:01\u001b[0m[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
      "Building wheels for collected packages: bayesmark\n",
      "  Building wheel for bayesmark (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for bayesmark: filename=bayesmark-0.0.8-py3-none-any.whl size=104281 sha256=9be2680d4d258437d58004597958b5bef7d0ea87d32a536deac291b9c22f9694\n",
      "  Stored in directory: /Users/kentrachmat/Library/Caches/pip/wheels/6c/62/5a/3ecc5022d645b5e44edba3472c7d14f8981ca15fc8b2dbcfcd\n",
      "Successfully built bayesmark\n",
      "Installing collected packages: smmap, pathvalidate, gitdb, GitPython, bayesmark\n",
      "Successfully installed GitPython-3.1.41 bayesmark-0.0.8 gitdb-4.0.11 pathvalidate-3.2.0 smmap-5.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install bayesmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bayesmark.random_search as rs\n",
    "from bayesmark import np_util\n",
    "from bayesmark.abstract_optimizer import AbstractOptimizer\n",
    "from bayesmark.experiment import experiment_main\n",
    "\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OurOptimizer(AbstractOptimizer):\n",
    "    # Unclear what is best package to list for primary_import here.\n",
    "    primary_import = \"bayesmark\"\n",
    "\n",
    "    def __init__(self, api_config, random=np_util.random):\n",
    "        \"\"\"Build wrapper class to use random search function in benchmark.\n",
    "\n",
    "        Settings for `suggest_dict` can be passed using kwargs.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        api_config : dict-like of dict-like\n",
    "            Configuration of the optimization variables. See API description.\n",
    "        \"\"\"\n",
    "        AbstractOptimizer.__init__(self, api_config)\n",
    "        self.random = random\n",
    "        self.meta_model = GaussianProcessRegressor(kernel=Matern(nu=2.5))\n",
    "        self.api_config = api_config\n",
    "        self.X = np.empty((0, len(api_config)))  # Storing input points\n",
    "        self.y = np.empty((0, 1)) \n",
    "        self.lb, self.ub = self.extract_bounds(api_config)\n",
    "\n",
    "        self.preprocessor_dict = self.build_preprocessor(api_config)\n",
    "\n",
    "    def process(self, x):\n",
    "        features = []\n",
    "        for feature in self.api_config:\n",
    "            feature_values = x[feature]\n",
    "            features.append(self.preprocessor_dict[feature](feature_values))\n",
    "        return features\n",
    "\n",
    "    def build_preprocessor(self, api_config):\n",
    "        processing_dict = {}\n",
    "        for feature in api_config:\n",
    "            if api_config[feature]['type'] == 'bool':\n",
    "                processing_dict[feature] = lambda x: int(x)\n",
    "\n",
    "            elif api_config[feature]['type'] == 'cat':\n",
    "                processing_dict[feature] = self.categorical_processing(api_config[feature]['values'])\n",
    "\n",
    "            elif api_config[feature]['type'] == 'int':\n",
    "                if 'range' in api_config[feature]:\n",
    "                    min_val, max_val = api_config[feature]['range']\n",
    "                    processing_dict[feature] =  self.min_max_processing(min_val, max_val)\n",
    "\n",
    "            elif api_config[feature]['type'] == 'real':\n",
    "                if 'range' in api_config[feature]:\n",
    "                    min_val, max_val = api_config[feature]['range']\n",
    "                    if api_config[feature]['space'] == 'log':\n",
    "                        min_val = np.log10(min_val)\n",
    "                        max_val = np.log10(max_val)\n",
    "                        processing_dict[feature] =  lambda x: self.min_max_processing(min_val, max_val)(np.log10(x))\n",
    "                    else:\n",
    "                        processing_dict[feature] =  self.min_max_processing(min_val, max_val)\n",
    "\n",
    "                else:\n",
    "                    processing_dict[feature] = lambda x: x\n",
    "                \n",
    "        return processing_dict\n",
    "\n",
    "    def categorical_processing(self, cats):\n",
    "        def process(x):\n",
    "            return cats.index(x)\n",
    "        return process\n",
    "    \n",
    "    def min_max_processing(self, min_val, max_val):\n",
    "        def process(x):\n",
    "            return (x - min_val) / (max_val - min_val)\n",
    "        return process\n",
    "\n",
    "    def suggest(self, n_suggestions=1):\n",
    "        \"\"\"Get suggestion.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_suggestions : int\n",
    "            Desired number of parallel suggestions in the output\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        next_guess : list of dict\n",
    "            List of `n_suggestions` suggestions to evaluate the objective\n",
    "            function. Each suggestion is a dictionary where each key\n",
    "            corresponds to a parameter being optimized.\n",
    "        \"\"\"\n",
    "        if len(self.X) > 0 and len(self.y) > 0:\n",
    "            # Sample new points using MCMC after at least one observation\n",
    "            sampled_points = self.mcmc_sample(n_suggestions)\n",
    "            next_guess = [self.convert_to_dict(point) for point in sampled_points]\n",
    "        else:\n",
    "            # Use a random initialization strategy for the first suggestion\n",
    "            next_guess = self.random_initialization(n_suggestions)\n",
    "        return next_guess\n",
    "\n",
    "\n",
    "    def observe(self, X, y):\n",
    "        \"\"\"Feed an observation back.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : list of dict-like\n",
    "            Places where the objective function has already been evaluated.\n",
    "            Each suggestion is a dictionary where each key corresponds to a\n",
    "            parameter being optimized.\n",
    "        y : array-like, shape (n,)\n",
    "            Corresponding values where objective has been evaluated\n",
    "        \"\"\"\n",
    "        X_p = np.array([self.process(x) for x in X])\n",
    "        self.X = np.vstack((self.X, X_p))\n",
    "        self.y = np.append(self.y, y)\n",
    "\n",
    "        if self.X.shape[0] > 0 and self.y.shape[0] > 0:\n",
    "            self.meta_model.fit(self.X, self.y)\n",
    "            \n",
    "    def mcmc_sample(self, n_suggestions):\n",
    "        # Start from a random point\n",
    "        current_point = np.random.uniform(self.lb, self.ub)\n",
    "        current_ei = self.expected_improvement(current_point.reshape(1, -1))\n",
    "\n",
    "        samples = [current_point]\n",
    "        for _ in range(n_suggestions - 1):\n",
    "            # Propose a new point\n",
    "            new_point = np.random.uniform(self.lb, self.ub)\n",
    "            new_ei = self.expected_improvement(new_point.reshape(1, -1))\n",
    "\n",
    "            # Accept new point with probability min(1, new_ei/current_ei)\n",
    "            if new_ei > current_ei or np.random.uniform(0, 1) < new_ei / current_ei:\n",
    "                current_point, current_ei = new_point, new_ei\n",
    "\n",
    "            samples.append(current_point)\n",
    "\n",
    "        return np.array(samples)\n",
    "\n",
    "    def expected_improvement(self, X, xi=0.01):\n",
    "        mu, sigma = self.meta_model.predict(X, return_std=True)\n",
    "        mu_sample = self.meta_model.predict(self.X)\n",
    "\n",
    "        mu_sample_opt = np.max(mu_sample)\n",
    "\n",
    "        with np.errstate(divide='warn'):\n",
    "            imp = mu - mu_sample_opt - xi\n",
    "            Z = imp / sigma\n",
    "            ei = imp * norm.cdf(Z) + sigma * norm.pdf(Z)\n",
    "            ei[sigma == 0.0] = 0.0\n",
    "\n",
    "        return ei\n",
    "    \n",
    "    def random_initialization(self, n_suggestions):\n",
    "        # Randomly sample points within the bounds\n",
    "        random_points = np.random.uniform(self.lb, self.ub, (n_suggestions, len(self.api_config)))\n",
    "        return [self.convert_to_dict(point) for point in random_points]\n",
    "\n",
    "    def convert_to_dict(self, point):\n",
    "        # Convert a point from array format to dictionary format\n",
    "        return {feature: point[i] for i, feature in enumerate(self.api_config)}\n",
    "    \n",
    "    def extract_bounds(self, api_config):\n",
    "        lb = []\n",
    "        ub = []\n",
    "        for feature, config in api_config.items():\n",
    "            if config['type'] in ['int', 'real']:\n",
    "                f_lb, f_ub = config['range']\n",
    "                lb.append(f_lb)\n",
    "                ub.append(f_ub)\n",
    "            elif config['type'] == 'bool':\n",
    "                lb.append(0)\n",
    "                ub.append(1)\n",
    "            elif config['type'] == 'cat':\n",
    "                lb.append(0)\n",
    "                ub.append(len(config['values']) - 1)\n",
    "            else:\n",
    "                raise ValueError(f\"Unsupported type: {config['type']}\")\n",
    "        return np.array(lb), np.array(ub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'x1': -1.4369032587547403,\n",
       "  'x2': -1.945879753432994,\n",
       "  'x3': -0.29051284370368124,\n",
       "  'x4': 1.3536730814763303}]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.random.normal(size=(50, 4))\n",
    "y = 3 * X[:, 0] + np.sin(X[:, 1]) + 2 * X[:, 2]**2 + np.random.normal(size=50)\n",
    "X = [{'x1': x[0], 'x2': x[1], 'x3': x[2], 'x4': x[3]} for x in X]\n",
    "\n",
    "optimizer = OurOptimizer({'x1': {'type': 'real', 'space': 'linear', 'range': (-3, 3)}, 'x2': {'type': 'real', 'space': 'linear', 'range': (-3, 3)}, 'x3': {'type': 'real', 'space': 'linear', 'range': (-3, 3)}, 'x4': {'type': 'real', 'space': 'linear', 'range': (-3, 3)}})\n",
    "optimizer.observe(X[:1], y[:1])\n",
    "optimizer.suggest(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aoml1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
